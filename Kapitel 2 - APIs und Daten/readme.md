# Kapitel 2: APIs, Webseiten-Scraping und eigene APIs und Webseiten

In Kapitel 2 unseres Python-Kurses werden wir uns mit verschiedenen Themen rund um APIs, Webseiten-Scraping und dem Erstellen eigener APIs und Webseiten beschäftigen. Diese Fähigkeiten sind äußerst nützlich, um Daten aus dem Internet abzurufen, zu verarbeiten und eigene Anwendungen zu erstellen.

## Lernziele
In diesem Kapitel werden wir Folgendes lernen:
- Wie wir mit APIs arbeiten und Daten von externen Diensten abrufen können.
- Wie wir Webseiten scrapen, um Daten daraus zu extrahieren.
- Wie wir eine eigene API schreiben, um Daten für andere Entwickler zugänglich zu machen.
- Wie wir eine eigene Webseite erstellen, um Informationen zu präsentieren.

## Anwendungsbeispiele
In diesem Kapitel werden wir zwei praktische Anwendungen programmieren:
1. **10-Tages Wetterprognose Service**: Wir werden einen Service entwickeln, der mithilfe einer Webseite und einer API eine 10-Tages Wetterprognose für eine bestimmte Region ausgibt.
2. **Rumors Webseite**: Wir werden eine Webseite namens "Rumors" erstellen, auf der Benutzer anonym Gerüchte verbreiten können.

## Lernabschnitte
Das Kapitel gliedert sich in folgende Abschnitte:

1. Verarbeiten von Excel-Tabellen mit pandas: Wir werden lernen, wie wir Excel-Tabellen mithilfe der Pandas-Bibliothek verarbeiten und analysieren können. Hierbei verwenden wir als Beispiel eine Excel-Tabelle mit regionalen Daten vom Statistischen Bundesamt.

2. Scraping mit requests und re: Wir werden uns anschauen, wie wir mithilfe der `requests`-Bibliothek und regulären Ausdrücken (`re`) Daten von Webseiten extrahieren können. Als Beispiel verwenden wir eine Webseite des Deutschen Wetterdienstes, von der wir Klimadaten abrufen möchten.

3. Vorstellung von Flask: Flask ist ein Webframework für Python. Wir werden die Grundlagen von Flask kennenlernen und verstehen, wie wir Webanwendungen mit diesem Framework erstellen können.

4. Erster API-Endpunkt: Wir werden unseren ersten API-Endpunkt mit Flask erstellen. Dabei lernen wir, wie wir Daten über eine API zugänglich machen und sie von anderen Entwicklern abrufen können.

5. Vorstellung von Postman: Postman ist ein Tool, das uns beim Testen von APIs unterstützt. Wir werden lernen, wie wir Postman verwenden können, um unsere eigenen APIs zu testen und Anfragen an sie zu senden.

6. Das CRUD-Modell: CRUD steht für Create, Read, Update und Delete. Wir werden verstehen, wie wir diese grundlegenden Operationen in unserer API implementieren können, um Daten zu erstellen, abzurufen, zu aktualisieren und zu löschen.

7. Authentifizierung: Wir werden die Grundlagen der Authentifizierung in Webanwendungen kennenlernen. Dabei diskutieren wir die Verwendung von Hash-Funktionen und den Einsatz von Salts, um Passwörter sicher zu speichern.

8. Templates: In diesem Abschnitt lernen wir, wie wir Templates verwenden können, um dynamische Webseiten zu erstellen. Dabei werden wir uns mit der Verwendung von Variablen (`{{ var }}`) und dem Zugriff auf Formulardaten (`request.form`) befassen.